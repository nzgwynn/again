\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Matching in Cluster Randomized Trials Using the Goldilocks Approach},
            pdfauthor={S. Gwynn Sturdevant, Susan Huang, Richard Platt, Ken Kleinman},
            pdfkeywords={cluster-randomized trials, matching},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{plainnat}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}
  \title{Matching in Cluster Randomized Trials Using the Goldilocks Approach}
  \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
  \author{S. Gwynn Sturdevant, Susan Huang, Richard Platt, Ken Kleinman}
  \preauthor{\centering\large\emph}
  \postauthor{\par}
  \predate{\centering\large\emph}
  \postdate{\par}
  \date{June 21, 2017}


\begin{document}
\maketitle
\begin{abstract}
Matching in cluster-randomized trials (CRTs) is important, but there is
no best practice describing how to make matches. When baseline data is
available, we suggest a strategy that can be used to achieve the desired
balance between treatment and control groups across numerous potential
confounding variables. This strategy involves iteratively: 1) computing
the Mahalanobis distance, 2) finding the pairs that minimize the overall
within-pair distance; 3) rerandomizing multiple times to generate the
potential between-arm imbalance; then 4) reweighting the potential
confounders. To aid in the evaluation of step 3, we plot the between-arm
differences for each variable with a parallel-coordinates plot.
Investigators can compare plots of different weighting schemes to
determine the one that best suits their needs. We demonstrate
application of the approach with the Swap-Out trial.
\end{abstract}

\section{Introduction}\label{introduction}

Individually randomized trials (IRTs) with blinding are the ``strongest
study design available'' \citep{gatsonis2017methods} to test the
efficacy of a treatment or an intervention. Unfortunately, for design
reasons some interventions must be delivered to groups of subjects. In
these cases, it is at least cost-efficient and possibly scientifically
necessary to gather data on subjects that are correlated with one
another. For example, suppose education researchers need to evaluate
teacher training for elementary school teachers with respect to its
effect on literacy skills in third graders. Randomizing third graders to
treatment or control conditions would not be practical-- it would imply
training many, many, teachers, and ignoring the majority of students as
well as the variability of student within class. In addition, some rural
schools may have only one teacher, further complicating matters.
Instead, researchers would randomize teachers, schools, or counties to
the training or to the control condition and evaluate the effect on
multiple students in each classroom. Trials where groups are randomized
are called group-randomized or cluster-randomized trials (CRTs). Three
reasons for conducting a CRTs are: (i) implementation occurs at the
cluster level, (ii) to avoid contamination, and (iii) to measure
intervention effects among cluster members who do not receive treatment
\citep{balzer2012match, CRTrials2009}. CRTs are ``the gold standard when
allocation of identifiable groups is necessary''
\citep{murray2004design}.

One challenge in CRTs is their limited sample size of randomizable
units. Most CRTs have less than 30 independent units to randomize,
though each unit may have thousands of individuals
\citep{balzer2012match}. In large IRTs, investigators expect
randomization to balance confounders across each arm of the trial. The
smaller number of randomizable units in CRTs makes imbalance a threat to
the causal interpretation of any observed treatment effect. Stratified
randomization, in which similar units are grouped together prior to
randomization, is one solution to this. Scholars debate the sizes of
these groups. In particular there is discussion about the merits of
matching, which involves grouping 2 units together, vs.~stratification,
where many more than 2 units are grouped\citep{PMVsStrat}. This article
discusses matching.

Many authors debate the value of matching at all in CRTs
\citep{balzer2012match, CRTrials2009, gatsonis2017methods, diehr1995breaking, murray1998design, imai2009essential, PMVsStrat, donner2007merits, klar1997merits, donner2000design, martin1993effect}.
Murray argues that ``the choice of matching or stratification {[}of{]}
factors is critical to the success of the procedure''
\citep{murray1998design}. Others suggest that caution must be used when
matching a small number of clusters due to the decrease in power
\citep{donner2000design, klar1997merits, balzer2012match, martin1993effect}.
Breaking the matches, i.e., ignoring the matching during data analysis,
addresses this \citep{diehr1995breaking}, but perhaps only when there
are a small number of large clusters \citep{donner2007merits}. Imai et
al. argue that not matching, in small or large samples, is ``equivalent
to discarding a considerable fraction of one's data''
\citep{imai2009essential}. However, in one trial ``matching actually led
to a loss in statistical efficiency''
\citep[\citet{donner2000design}]{manun1994influence}. Despite all this
debate, few authors discuss how to match the clusters
\citep{raab2001balance}.

Our article is an extension of methods introduced previously
\citep{gatsonis2017methods}. We suggest a method suitable for
\(a \; priori\) matching using baseline data. In section 2 we outline
our method, section 3 applies it to data for the Swap-Out trial, and in
section 4 discuss the implications of our approach.

\section{Methods}\label{methods}

We suggest a new approach to the complex topic of balancing
randomization in CRTs. We match the clusters on many variables, using a
``weighting'' scheme to suggest which variables are most important. Then
we perform many ``false'' or practice randomizations to obtain a
distribution of the possible arm assignments that might be obtained when
official randomization occurs. Investigators assess these distributions
to determine if potential randomizations would result in sufficiently
balanced treatment assignments. If not, the weighting scheme is adjusted
and the process begins again. The details follow.

The initial step involves prioritizing variables \((1, 2,..., n)\) from
units \((1, 2, ..., m)\) to be randomized. We have

\begin{eqnarray*}
 V_1 & = & (v_{11}, v_{12},..., v_{1n})\\
 V_2 & = & (v_{21}, v_{22},..., v_{2n})\\
 \vdots & = & \vdots\\    
 V_m & = & (v_{m1}, v_{m2},..., v_{mn})\\
\end{eqnarray*}

where \(v_{ij}\) is the \(j^{th}\) variable from unit \(i\): each
\(V_i\) contains pertinent variables from unit \(i\). From here, we
compute the Mahalanobois distance between two units. This is the
generalized \(n\)-dimensional distance across the variables; for two
units \(a\) and \(b\) it is calculated as
\(d(V_a, V_b) = \sum_{k=1}^n \frac{(v_{ak} - v_{bk})^2}{s_k^2}\) where
\(s_k^2 = \frac{1}{m} \sum_{l=1}^m(v_{lk} - v_{\cdot k})\) and
\(v_{\cdot k} = \frac{1}{n} \sum_{i = 1}^m v_{ik}\). Then we find the
pairs of clusters that minimize the global Mahalanobis distance across
all of the pairs of clusters. This can be done in the R statistical
programming environment \citep{R} using the \texttt{nmatch} function in
the \texttt{designmatch} package \citep{nmatch}.

Once the matching is completed, we have pairs
\((C_{11}, C_{12}), (C_{21}, C_{22}), ..., (C_{\frac{m}{2}1}, C_{\frac{m}{2}2}),\)
where \(C_{ij}\) is the \(j\)th cluster in the \(i\)th pair. The first
match in each pair will be randomized to either treatment or control,
the second to the other arm. If cluster \(C_{11}\) is randomized to
treatment, we denote this as \(C_{11}^T\), and this implies
\(C_{12}^C\), where the superscript indicates either treatment (\(T\))
or control (\(C\)). Next, we find the per variable difference between
the two groups:

\begin{eqnarray*}
 d_j = \frac{| \sum_{i = 1}^{\frac{m}{2}}C_{ij}^T - \sum_{i = 1}^{\frac{m}{2}}C_{ij}^C |}{\frac{m}{2}} 
\end{eqnarray*}

for \(j = 1, 2, ..., n.\) This generates the vector
\(D = (d_1, \ldots, d_n)\) of the average pairwise difference between
the arms for each variable. When the trial is complete, these
differences are likely to be reported as evidence of the balance acieved
in the randomization. We repeat this process of randomization \(R\)
times and find \(D_r\), the vector of average differences between the
two arms for the \(r\)th re-randomization. To visualize we draw a
parallel coordinates plot where the \(j^{th}\) axis plots all \(D_r\)
for \(r = 1, 2, ..., R\), as shown in the Figures below.

The investigators may find the distribution of possible randomizations
unacceptable, for example because the mean distance between the arms is
too large, or the maximum distance is too large. In that case, we
introduce ``weights'' \(S = (s_{1}, s_{2},..., s_{n})\), which control
the strength of matching on each variable. We have

\begin{eqnarray*}
 v_{ij}^* = \prod_{i=1}^{m} v_{ij} \times s_j
\end{eqnarray*}

which we combine to form

\begin{eqnarray*}
 V_1^* & = & (v_{11}^*, v_{12}^*,..., v_{1n}^*) \\
 V_2^* & = & (v_{21}^*, v_{22}^*,..., v_{2n}^*) \\
 \vdots & = & \vdots\\    
 V_m^* & = & (v_{m1}^*, v_{m2}^*,..., v_{mn}^*) .\\
\end{eqnarray*}

If \(s_a > s_b\), this has the effect of increasing the distance between
units for variable \(a\), relative to variable \(b\). Then,
counter-intuitively, when we re-run the matching algorithm, we will get
closer matches for variable \(a\) than variable \(b\). After selecting
\(S\) We again find the between-arm differences for each variable,
\(D_r\) and plot them. The cost of a high weight for variable \(a\) in
this process is that closer matches for variable \(a\) are likely to
imply reduced closeness in another variable, so compromises must be
made.

\section{Results}\label{results}

To demonstrate the usefulness of this technique we present a brief
summary of our randomization process using baseline data from the
Swap-Out trial (Cluster-randomized Non-inferiority Trial Comparing
Mupirocin vs.~Iodophor for Nasal Decolonization of ICU Patients to
Assess Impact on Staphylococcus aureus Clinical Cultures and All-cause
Bloodstream Infection During Routine Chlorhexidine Bathing)
\citep{SOTrial}. In this non-inferiority trial, the investigators are
studying whether bathing with chlorhexidine gluconate and swabbing with
iodophor nasal swabs are an acceptable substitute for bathing with
chlorhexidine but swabbing with the antibiotic mupirocin. In the Reduce
trial \citep{huang2013targeted} mupirocin nasal swabs and bathing with
chlorhexidine reduced methycillin resistant Staphylococcus aureus in
Hospital Corporation of America intensive care units (ICU). However,
physicians are reluctant to use mupirocin, an antibiotic, so broadly, so
investigators are assessing ``swapping'' it with iodophor, a
disinfectant.

\begin{longtable}[]{@{}lllll@{}}
\caption{Abbreviations of variables used to randomize}\tabularnewline
\toprule
Primary & Secondary & Tertiary & Quaternary & Quinary\tabularnewline
\midrule
\endfirsthead
\toprule
Primary & Secondary & Tertiary & Quaternary & Quinary\tabularnewline
\midrule
\endhead
Pt Days & Median LOS & Medicaid & DC SNF & Onc\_BMT\_Trp\tabularnewline
S aur Rate & Comorbidity Score & PCR Blood & Surgery &
BMT\_Trp\tabularnewline
MRSA Rate &\tabularnewline
All Blood &\tabularnewline
Mup-R &\tabularnewline
Hx MRSA &\tabularnewline
Mup Adherence &\tabularnewline
CHG Adherence &\tabularnewline
\bottomrule
\end{longtable}

Data collected from electronic medical records and electronic billing
systems were available for matching prior to randomization. We used data
from 20 months from 137 hospitals whose administrators had consented to
participate. With this data, investigators met to prioritize baseline
variables into several categories, as shown in Table 1: primary,
secondary, tertiary, quaternary, quinary, and not relevant to
randomization. For this trial, the investigators decided that average
monthly attributable days (pt\_days), Staphylococcus aureus Intensive
Care Unit -attributable cultures per 1,000 days (S aur rate), MRSA
ICU-attributable cultures per 1,000 days (MRSA rate), all pathogen
ICU-attributable bacteremia cultures per 1,000 days (All Blood),
regional mupirocin resistance estimate (Mup-R), percent of admissions
with MRSA diagnosis within a year (Hx MRSA), percent of mupirocin use
admission to day 5 (Mup Adherence), and surveyed use of chlorhexidine
gluconate (CHG Adherence) were all of primary importance. Of secondary
importance were median ICU length of stay (Median LOS), and mean
Elixhauser total score (Comorbidity Score). Of tertiary importance were
the percentage of ICU medicaid patients (Medicaid), and whether or not a
facility uses polymerase chain reactions to identify MRSA in blood (PCR
Blood). The next group included percent admissions to skilled nursing
facility (DC SNF), and the percent of admissions with Center for Disease
Control and Prevention surveillance surgery (Surgery). The final group
included whether the ICU had specialty units for oncology, bone marrow
transplant, or transplant units (Onc\_BMT\_Trp), and if the ICU has bone
marrow transplant or transplant units (BMT\_Trp).

Prior to randomization, investigators spent time using a web app built
using the \texttt{Shiny} package in \texttt{R} that implements the
strategy described in section 2. This enabled the investigators to
quickly and easily change the weights applied to each potential matching
variable. The web app allows the investigators to set the bounds for
each axis as well as the weights. We recommend deciding on tolerable
maximum differences between study arms as well as desirable ranges of
differences for each variables and using many combinations of strengths
of matching until one is found which ensures randomization is likely to
satisfy. In the well-known children's fable The Three Bears, Goldilocks
tries three bowls of porridge, one is too hot, the other too cold, and
the third is just right \citep{3Bears}. We recommend a similar procedure
applied to strengths of matching, with perhaps more attempts.

\begin{figure}

{\centering \includegraphics{Bins_files/figure-latex/IntroGraph-1} 

}

\caption{Possible randomizations for 3 different weights. The top left has no weighting and two axises exceed maximum values. The top right is matched strongly on the middle axis and the first and third exceed. The bottom was used in Swap-Out.}\label{fig:IntroGraph}
\end{figure}

Figure 1 demonstrates this process using three variables: attributable
patient days per month, Staphylococcus aureus rate, and MRSA rate. After
initial explorations on the web application, investigators agreed that a
tolerable maximum mean difference between treatment and control arms for
these variables were: 80 attributable patient days per month, 0.15
difference in Staphylococcus aureus infection rates, and 0.15 difference
in MRSA rate. The graph on the top left shows the results of 300
re-randomizations when all the weights are equal, equivalent to using
the raw values of each variable. To read a parallel coordinates plot,
trace a single gray line from ``Pt Days'' to ``S aur rate'' to ``MRSA
rate''; this shows the between- arm differences obtained from a single
randomization. The values in the upper left show that several
randomizations exceeded the maximums in the second and third axis: there
is a reasonable chance that if randomization occurred with this
weighting the Staphylococcus aureus and MRSA rates would be imbalanced
between the treatment and control arms. To rectify this, positive
strengths must be added. In the top-right graph a strength of 8 has been
applied to the Staphylococcus aureus rate. In this graph, the matching
of hospitals is strongly adjusted so that hospitals with similar
Staphylococcus aureus rates are paired. This results in low mean
difference between the treatment and control arms in that variable. The
values on the middle axis are all well below the maximum value: if
randomization occurred using these strengths we are likely to get
suitable balance in this variable. Unfortunately, there is a penalty.
Hospitals with similar Staphylococcus aureus rates do not have similar
attributable patient days per month and MRSA rates, which results in a
few of these values exceeding the maximum. In particular, our
investigators felt that the chance of attaining MRSA rates above 0.15
were too high for these strengths. The bottom plot shows the possible
mean balances used in the actual randomization for these three
variables, the strengths of matching for each variable were 1, 4, and 2,
respectively. In all graphs, the black line indicates the mean value of
all points on each axis. We also use this value to help decide whether
the matching is acceptable.

Our investigators used this approach with all 16 variables shown in
Table 1. After trying many weights they chose one with an agreeable
balance between treatment and control arms for the variables of most
importance. The results can be seen in Figure 2. For all the variables,
none of the randomizations resulted in intolerable between-arm
differences, and for most, the mean difference was much closer to 0 than
the maximum tolerable. When the trial was randomized we used this
strength to match hospitals in the study, then randomized one member of
each match to treatment and the other to control.

One variable in Figure 2, median length of stay, has the same value for
all the re-randomizations. That is, for this variable, every assignment
of treatment and control within the pairs results in the same mean
difference in median length of stay between the control and treatment
arms. This is likely due to the very small variability on this
variable-- the vast majority of the hospitals had the same median length
of stay.

\begin{figure}

{\centering \includegraphics{Bins_files/figure-latex/FullGraph-1} 

}

\caption{Swap-Out investigators found weights used to make this possible randomization schema suitable.}\label{fig:FullGraph}
\end{figure}

\section{Discussion}\label{discussion}

While the Goldilocks approach to randomizing does not ensure balance in
the treatment and control arms, it is a tool that provides investigators
with a method to explore strengths of matching that impact matching and
balance. Investigators that use CRTs and plan to match can use this
method prior to randomizing to help ensure balance between treatment and
control arms.

If investigators would like to use this method on studies with more than
\(2\) arms, \(D_{r}\) can be redefined as, for example, the standard
deviation between among the arms.

In Swap-Out the number of units to randomize was odd. To address this,
our \texttt{Shiny} web application allowed our investigators to choose
if the unmatched unit was in the treatment or control arm. The \(D_{r}\)
was adjusted accordingly.

We plan to publish the \texttt{Shiny} web app described above for any
investigator to use. This application will eventually be an interactive
plot that enables users to click on each axis and view where low and
high draws of that variable fall for other variables.

\bibliography{bibliography}


\end{document}
